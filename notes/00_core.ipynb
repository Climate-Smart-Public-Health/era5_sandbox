{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This is a core library for the ERA5 dataset pipeline. It defines\n",
    "a few helpful functions such as an API tester to test your API key and connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import cdsapi\n",
    "import hydra\n",
    "import json\n",
    "import tempfile\n",
    "import geopandas as gpd\n",
    "from pydrive2.auth import GoogleAuth\n",
    "from pydrive2.drive import GoogleDrive\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pyprojroot import here\n",
    "from importlib import import_module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "Some utilities are provided to help you with the ERA5 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def describe(\n",
    "    cfg: DictConfig=None,  # Configuration file\n",
    "    )-> None:\n",
    "    \"Describe the configuration file used by Hydra for the pipeline\"\n",
    "    \n",
    "    if cfg is None:\n",
    "        print(\"No configuration file provided. Generating default configuration file.\")\n",
    "        cfg = OmegaConf.create()\n",
    "        \n",
    "    print(\"This package fetches ERA5 data. The following is the config file used by Hydra for the pipeline:\\n\")\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _expand_path(\n",
    "        path: str   # Path on user's machine\n",
    "        )->   str:  # Expanded path\n",
    "    \"Expand the path on the user's machine for cross compatibility\"\n",
    "\n",
    "    # Expand ~ to the user's home directory\n",
    "    path = os.path.expanduser(path)\n",
    "    # Expand environment variables\n",
    "    path = os.path.expandvars(path)\n",
    "    # Convert to absolute path\n",
    "    path = os.path.abspath(path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _get_callable(func_path):\n",
    "    \"\"\"Dynamically import a callable from a string path.\"\"\"\n",
    "    module_name, func_name = func_path.rsplit(\".\", 1)\n",
    "    module = import_module(module_name)\n",
    "    return getattr(module, func_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def _create_directory_structure(\n",
    "        base_path: str,  # The base directory where the structure will be created\n",
    "        structure: dict  # A dictionary representing the directory structure\n",
    "    )->None:\n",
    "    \"\"\"\n",
    "    Recursively creates a directory structure from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): The base directory where the structure will be created.\n",
    "        structure (dict): A dictionary representing the directory structure.\n",
    "    \"\"\"\n",
    "    for folder, substructure in structure.items():\n",
    "        # Create the current directory\n",
    "        current_path = os.path.join(base_path, folder)\n",
    "        os.makedirs(current_path, exist_ok=True)\n",
    "        \n",
    "        # Recursively create subdirectories if substructure is a dictionary\n",
    "        if isinstance(substructure, dict):\n",
    "            _create_directory_structure(current_path, substructure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Class for Authenticating Google Drive\n",
    "\n",
    "We're going to use a class to authenticate and interact with google drive. The goal is to have a simple interface to fetch the healthshed files dynamically from google drive in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class GoogleDriver:\n",
    "    \"\"\"\n",
    "    A class to handle Google Drive authentication and file management.\n",
    "    This class uses the PyDrive2 library to authenticate with Google Drive using a service account.\n",
    "    \n",
    "    It provides three methods: authenticating the account, getting the drive object, and downloading the healthshed files for madagascar.\n",
    "    \"\"\"\n",
    "    def __init__(self, json_key_path=None):\n",
    "        self.json_key_path = json_key_path or os.getenv(\"GOOGLE_DRIVE_AUTH_JSON\")\n",
    "        if not self.json_key_path or not os.path.isfile(self.json_key_path):\n",
    "            raise FileNotFoundError(f\"Service account key file not found: {self.json_key_path}\")\n",
    "        self.drive = self._authenticate()\n",
    "\n",
    "    def _authenticate(self):\n",
    "\n",
    "        settings = {\n",
    "            \"client_config_backend\": \"service\",\n",
    "            \"service_config\": {\n",
    "                \"client_json_file_path\": self.json_key_path\n",
    "            }\n",
    "        }\n",
    "        gauth = GoogleAuth(settings=settings)\n",
    "\n",
    "        gauth.ServiceAuth()\n",
    "        \n",
    "        return GoogleDrive(gauth)\n",
    "\n",
    "    def get_drive(self):\n",
    "        return self.drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we use it. The credentials for the data-pipeline service account are\n",
    "available in the sandbox folder, and the path to said folder is set in the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# unfortunately, we have to use the initialize function to load the config file\n",
    "# this is because the @hydra decorator does not work with Notebooks very well\n",
    "# this is a known issue with Hydra: https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "# \n",
    "# just use the relative path from the notebook to the config dir\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name='config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = GoogleDriver(json_key_path=here() / cfg.GOOGLE_DRIVE_AUTH_JSON.path)\n",
    "drive = auth.get_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we might check that the healthsheds are accessible in the drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthsheds2022.zip (1v2y-WhsTQxYyj8AWQPYkoVH0l-542IUQ) - application/zip\n"
     ]
    }
   ],
   "source": [
    "folder_id = cfg.GOOGLE_DRIVE_AUTH_JSON.healthsheds_id\n",
    "folder_name = \"healthsheds2022.zip\"\n",
    "file_list = drive.ListFile({'q': f\" title='{folder_name}' and trashed = false \"}).GetList()\n",
    "\n",
    "for file in file_list:\n",
    "    print(f\"{file['title']} - {file['mimeType']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That being said, we can read in  the healthsheds into geopandas by downloading them to a temp directory. The healthsheds must be a zipped shapefiles package with the files at the root of the zip directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    # Create a temporary directory to store the downloaded file\n",
    "    zip_path = os.path.join(temp_dir, folder_name)\n",
    "\n",
    "    # Download file from Google Drive\n",
    "    file_obj = drive.CreateFile({'id': file_list[0]['id']})\n",
    "    file_obj.GetContentFile(zip_path)\n",
    "\n",
    "    # Read shapefile directly from ZIP\n",
    "    gdf = gpd.read_file(f\"zip://{zip_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works! So now we can patch the class to include this workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def read_healthsheds(self:GoogleDriver, healthshed_zip_name):\n",
    "\n",
    "    file_list = self.drive.ListFile({'q': f\" title='{healthshed_zip_name}' and trashed = false \"}).GetList()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Create a temporary directory to store the downloaded file\n",
    "        zip_path = os.path.join(temp_dir, healthshed_zip_name)\n",
    "\n",
    "        # Download file from Google Drive\n",
    "        file_obj = self.drive.CreateFile({'id': file_list[0]['id']})\n",
    "        file_obj.GetContentFile(zip_path)\n",
    "\n",
    "        # Read shapefile directly from ZIP\n",
    "        gdf = gpd.read_file(f\"zip://{zip_path}\")\n",
    "\n",
    "        # we need to ensure that the healthsheds only contain valid polygons\n",
    "        gdf = gdf[gdf.geometry.notnull()]\n",
    "        gdf.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to check that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fs_uid</th>\n",
       "      <th>fs_pop</th>\n",
       "      <th>n_uid</th>\n",
       "      <th>n_instat</th>\n",
       "      <th>reg_uid</th>\n",
       "      <th>reg_name</th>\n",
       "      <th>dist_uid</th>\n",
       "      <th>dist_name</th>\n",
       "      <th>fs_type</th>\n",
       "      <th>fs_name</th>\n",
       "      <th>fs_ll</th>\n",
       "      <th>n_comp</th>\n",
       "      <th>n_shape</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0YU5ksfXZS</td>\n",
       "      <td>13014</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>O0yrAFTjghG</td>\n",
       "      <td>Vatovavy</td>\n",
       "      <td>hBOXdumAvNc</td>\n",
       "      <td>Mananjary</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Morafeno</td>\n",
       "      <td>POINT (48.180332 -21.097472)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((48.21537 -20.95662, 48.21593 -20.956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1SY9AiVPYF</td>\n",
       "      <td>3103</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I9lEj4mALls</td>\n",
       "      <td>Analamanga</td>\n",
       "      <td>vHRv6NgA70x</td>\n",
       "      <td>Manjakandriana</td>\n",
       "      <td>CSB1</td>\n",
       "      <td>CSB1 Ambohidraisolo</td>\n",
       "      <td>POINT (47.879317 -19.161348)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((47.85923 -19.09954, 47.8601 -19.0998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38WhL0NPsX</td>\n",
       "      <td>2344</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>O0yrAFTjghG</td>\n",
       "      <td>Vatovavy</td>\n",
       "      <td>hBOXdumAvNc</td>\n",
       "      <td>Mananjary</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Mahatsara Iefaka</td>\n",
       "      <td>POINT (48.326937 -21.11468)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((48.35588 -21.05353, 48.35801 -21.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6fVNQgqqJg</td>\n",
       "      <td>7494</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>kgGIXgdG56r</td>\n",
       "      <td>Haute Matsiatra</td>\n",
       "      <td>BU35owjfn8G</td>\n",
       "      <td>Vohibato</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Ankaromalaza</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((47.18552 -21.70624, 47.19275 -21.711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A77QRkmKUul</td>\n",
       "      <td>8387</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>I9lEj4mALls</td>\n",
       "      <td>Analamanga</td>\n",
       "      <td>dsDbxSkO1ST</td>\n",
       "      <td>Andramasina</td>\n",
       "      <td>CSB1</td>\n",
       "      <td>CSB1 Mangabe</td>\n",
       "      <td>POINT (47.716094 -19.176215)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((47.73249 -19.15372, 47.73267 -19.153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>zw74in2A9Vn</td>\n",
       "      <td>4580</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>A8UMJuP8iI3</td>\n",
       "      <td>Boeny</td>\n",
       "      <td>ffiVmdBUwzI</td>\n",
       "      <td>Marovoay</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Ampijoroa Nord</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((46.73145 -16.12848, 46.73365 -16.131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>zwhfpU5j9aV</td>\n",
       "      <td>7440</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>PTqLWwjcAox</td>\n",
       "      <td>Anosy</td>\n",
       "      <td>KBe7h4EfJDf</td>\n",
       "      <td>Taolagnaro</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Tanandava</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((47.00558 -24.44654, 47.00489 -24.446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>zwyM0iDw9X7</td>\n",
       "      <td>5705</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>wR0PL2iap0s</td>\n",
       "      <td>Atsinanana</td>\n",
       "      <td>xgvRu8zZAZK</td>\n",
       "      <td>Marolambo</td>\n",
       "      <td>CSB1</td>\n",
       "      <td>CSB1 Maroariana I</td>\n",
       "      <td>POINT (47.948408 -20.025144)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((47.95335 -19.9937, 47.95573 -20.0087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>zxQu4lRMMP9</td>\n",
       "      <td>7647</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>zJ9UJ7RhCwV</td>\n",
       "      <td>Diana</td>\n",
       "      <td>s3HejcPkUeJ</td>\n",
       "      <td>Antsiranana II</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Antsalaka</td>\n",
       "      <td>POINT (49.251201 -12.640404)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((49.27604 -12.6479, 49.27603 -12.6479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>zywLk4jVk8O</td>\n",
       "      <td>8714</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>gHNBsfuG0Cz</td>\n",
       "      <td>Betsiboka</td>\n",
       "      <td>SrAluezWP64</td>\n",
       "      <td>Maevatanana</td>\n",
       "      <td>CSB2</td>\n",
       "      <td>CSB2 Bemokotra</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((46.78569 -17.06743, 46.78644 -17.069...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2773 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fs_uid  fs_pop  n_uid  n_instat      reg_uid         reg_name  \\\n",
       "0     A0YU5ksfXZS   13014      6         6  O0yrAFTjghG         Vatovavy   \n",
       "1     A1SY9AiVPYF    3103      4         4  I9lEj4mALls       Analamanga   \n",
       "2     A38WhL0NPsX    2344      3         3  O0yrAFTjghG         Vatovavy   \n",
       "3     A6fVNQgqqJg    7494      5         5  kgGIXgdG56r  Haute Matsiatra   \n",
       "4     A77QRkmKUul    8387      5         4  I9lEj4mALls       Analamanga   \n",
       "...           ...     ...    ...       ...          ...              ...   \n",
       "2768  zw74in2A9Vn    4580      5         5  A8UMJuP8iI3            Boeny   \n",
       "2769  zwhfpU5j9aV    7440      5         5  PTqLWwjcAox            Anosy   \n",
       "2770  zwyM0iDw9X7    5705      3         3  wR0PL2iap0s       Atsinanana   \n",
       "2771  zxQu4lRMMP9    7647      6         5  zJ9UJ7RhCwV            Diana   \n",
       "2772  zywLk4jVk8O    8714      9         9  gHNBsfuG0Cz        Betsiboka   \n",
       "\n",
       "         dist_uid       dist_name fs_type                fs_name  \\\n",
       "0     hBOXdumAvNc       Mananjary    CSB2          CSB2 Morafeno   \n",
       "1     vHRv6NgA70x  Manjakandriana    CSB1    CSB1 Ambohidraisolo   \n",
       "2     hBOXdumAvNc       Mananjary    CSB2  CSB2 Mahatsara Iefaka   \n",
       "3     BU35owjfn8G        Vohibato    CSB2      CSB2 Ankaromalaza   \n",
       "4     dsDbxSkO1ST     Andramasina    CSB1           CSB1 Mangabe   \n",
       "...           ...             ...     ...                    ...   \n",
       "2768  ffiVmdBUwzI        Marovoay    CSB2    CSB2 Ampijoroa Nord   \n",
       "2769  KBe7h4EfJDf      Taolagnaro    CSB2         CSB2 Tanandava   \n",
       "2770  xgvRu8zZAZK       Marolambo    CSB1      CSB1 Maroariana I   \n",
       "2771  s3HejcPkUeJ  Antsiranana II    CSB2         CSB2 Antsalaka   \n",
       "2772  SrAluezWP64     Maevatanana    CSB2         CSB2 Bemokotra   \n",
       "\n",
       "                             fs_ll  n_comp  n_shape  \\\n",
       "0     POINT (48.180332 -21.097472)     1.0        1   \n",
       "1     POINT (47.879317 -19.161348)     1.0        1   \n",
       "2      POINT (48.326937 -21.11468)     1.0        1   \n",
       "3                             None     1.0        1   \n",
       "4     POINT (47.716094 -19.176215)     1.0        1   \n",
       "...                            ...     ...      ...   \n",
       "2768                          None     1.0        1   \n",
       "2769                          None     1.0        1   \n",
       "2770  POINT (47.948408 -20.025144)     1.0        1   \n",
       "2771  POINT (49.251201 -12.640404)     1.0        1   \n",
       "2772                          None     1.0        1   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((48.21537 -20.95662, 48.21593 -20.956...  \n",
       "1     POLYGON ((47.85923 -19.09954, 47.8601 -19.0998...  \n",
       "2     POLYGON ((48.35588 -21.05353, 48.35801 -21.057...  \n",
       "3     POLYGON ((47.18552 -21.70624, 47.19275 -21.711...  \n",
       "4     POLYGON ((47.73249 -19.15372, 47.73267 -19.153...  \n",
       "...                                                 ...  \n",
       "2768  POLYGON ((46.73145 -16.12848, 46.73365 -16.131...  \n",
       "2769  POLYGON ((47.00558 -24.44654, 47.00489 -24.446...  \n",
       "2770  POLYGON ((47.95335 -19.9937, 47.95573 -20.0087...  \n",
       "2771  POLYGON ((49.27604 -12.6479, 49.27603 -12.6479...  \n",
       "2772  POLYGON ((46.78569 -17.06743, 46.78644 -17.069...  \n",
       "\n",
       "[2773 rows x 14 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = GoogleDriver(json_key_path=here() / cfg.GOOGLE_DRIVE_AUTH_JSON.path)\n",
    "drive = driver.get_drive()\n",
    "healthsheds = driver.read_healthsheds(\"healthsheds2022.zip\")\n",
    "\n",
    "healthsheds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests and Main\n",
    "\n",
    "In `nbdev`, our tests are embedded in the notebook. Whenever you export the notebook, all the cells that are specified to run are run, and hence, the tests are executed. The tests are also exported. This is a great way to ensure that your documentation is always up-to-date. For this module, we're using the `testAPI()` function as our main test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def testAPI(\n",
    "    cfg: DictConfig=None,\n",
    "    dataset:str=\"reanalysis-era5-pressure-levels\"\n",
    "    )-> bool:    \n",
    "    \n",
    "    # parse config\n",
    "    testing=cfg.development_mode\n",
    "    output_path=here(\"data\") / \"testing\"\n",
    "\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    try:\n",
    "        client = cdsapi.Client()\n",
    "\n",
    "        # build request\n",
    "        request = {\n",
    "            'product_type': ['reanalysis'],\n",
    "            'variable': ['geopotential'],\n",
    "            'year': ['2024'],\n",
    "            'month': ['03'],\n",
    "            'day': ['01'],\n",
    "            'time': ['13:00'],\n",
    "            'pressure_level': ['1000'],\n",
    "            'data_format': 'grib',\n",
    "        }\n",
    "\n",
    "        target = output_path / 'test_download.grib'\n",
    "        \n",
    "        print(\"Testing API connection by downloading a dummy dataset to {}...\".format(output_path))\n",
    "\n",
    "        client.retrieve(dataset, request, target)\n",
    "\n",
    "        if not testing:\n",
    "            os.remove(target)\n",
    "        \n",
    "        print(\"API connection test successful.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"API connection test failed.\")\n",
    "        print(\"Did you set up your API key with CDS? If not, please visit https://cds.climate.copernicus.eu/how-to-api#install-the-cds-api-client\")\n",
    "        print(\"Error: {}\".format(e))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this API tester tool works with Hydra configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This package fetches ERA5 data. The following is the config file used by Hydra for the pipeline:\n",
      "\n",
      "query:\n",
      "  product_type: reanalysis\n",
      "  variable:\n",
      "  - 2m_dewpoint_temperature\n",
      "  - 2m_temperature\n",
      "  - skin_temperature\n",
      "  - total_precipitation\n",
      "  year:\n",
      "  - 2010\n",
      "  - 2011\n",
      "  month:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "  - 6\n",
      "  - 7\n",
      "  - 8\n",
      "  - 9\n",
      "  - 10\n",
      "  - 11\n",
      "  - 12\n",
      "  day:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "  - 6\n",
      "  - 7\n",
      "  - 8\n",
      "  - 9\n",
      "  - 10\n",
      "  - 11\n",
      "  - 12\n",
      "  - 13\n",
      "  - 14\n",
      "  - 15\n",
      "  - 16\n",
      "  - 17\n",
      "  - 18\n",
      "  - 19\n",
      "  - 20\n",
      "  - 21\n",
      "  - 22\n",
      "  - 23\n",
      "  - 24\n",
      "  - 25\n",
      "  - 26\n",
      "  - 27\n",
      "  - 28\n",
      "  - 29\n",
      "  - 30\n",
      "  - 31\n",
      "  time:\n",
      "  - 0\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "  - 6\n",
      "  - 7\n",
      "  - 8\n",
      "  - 9\n",
      "  - 10\n",
      "  - 11\n",
      "  - 12\n",
      "  - 13\n",
      "  - 14\n",
      "  - 15\n",
      "  - 16\n",
      "  - 17\n",
      "  - 18\n",
      "  - 19\n",
      "  - 20\n",
      "  - 21\n",
      "  - 22\n",
      "  - 23\n",
      "  area:\n",
      "  - 0\n",
      "  - 360\n",
      "  - -90\n",
      "  - 90\n",
      "  data_format: netcdf\n",
      "  download_format: unarchived\n",
      "datapaths:\n",
      "  input: null\n",
      "  output: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# unfortunately, we have to use the initialize function to load the config file\n",
    "# this is because the @hydra decorator does not work with Notebooks very well\n",
    "# this is a known issue with Hydra: https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "# \n",
    "# just use the relative path from the notebook to the config dir\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "describe(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Main Function\n",
    "\n",
    "Important: using `__main__` in nbdev and Hydra is a little bit tricky. We need to define the main function in the module ONLY ONCE and then when we export the notebook to script, we need to add the `nbdev.imports.IN_NOTEBOOK` variable. This way, the main function will only be executed when we run the notebook and not when we import the module.\n",
    "\n",
    "```python\n",
    "from nbdev.imports import IN_NOTEBOOK\n",
    "```\n",
    "\n",
    "You'll see this listed throughout the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@hydra.main(version_base=None, config_path=\"../../conf\", config_name=\"config\")\n",
    "def main(cfg: DictConfig) -> None:\n",
    "\n",
    "    # Create the directory structure\n",
    "    _create_directory_structure(here() / \"data\", cfg.datapaths)\n",
    "\n",
    "    # test the api\n",
    "    testAPI(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era5_sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
